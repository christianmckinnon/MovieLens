# R Code for the HarvardX Capstone MovieLens Project

###################################################

# Note:
# A detailed introduction, sections on methods & analysis, modeling
# explanations and a conclusion can be found in my RMD and PDF reports.
# This is simply the code written to generate the figures of those reports!

###################################################

### Introduction ###
# It was back in October of 2006 when Netflix issued its now famous challenge: one million dollars for a machine learning algorithm that could improve their movie recommendation system by 10% or more.
# The challenge immediately attracted tech enthusiasts, statisticians, academics and even the mainstream media.
# The thought of parsing through millions of movie ratings generated by hundreds of thousands of users was uncharted territory at the time.
# Though Netflix ultimately never implemented the winning algorithm, the challenge itself spurred a new era of breakthroughs in artificial intelligence and its subset machine learning.
# In this project for the Capstone course of the HarvardX Professional Certificate in Data Science (PH125.9x), we will explore and visually examine the MovieLens data set of GroupLens Research which features over 10 million ratings.
# Our objective will be to develop a machine-learning model by creating train and test sets to predict movie ratings on a validation set that achieves a Root Mean Square Error (RMSE) of less than .8649.
# Mathematically, the RMSE is the standard deviation of the prediction errors (residuals) and is used to measure the difference between observed and predicted values.
# It is a popular metric to gauge the effectiveness of machine-learning models and was used to benchmark competing models for the Netflix Challenge.
# The dataset, titled "MovieLens," was developed by researchers at the University of Minnesota and was designed to generate personalized film recommendations.
# According to GroupLens, the December 2019 release contains over 25 million ratings and 1 million tag applications applied to 62,000 movies and 162,000 users.
# For the academic purposes of this course, we will be exploring the "MovieLens 10M Dataset."

### Methods & Analysis ###
# First, we will begin by preparing the data and loading it from the [GroupLens Website](https://grouplens.org/datasets/movielens/10m/).
# The data will initially be split into datasets titled "edx" and "validation" before being further partitioned into training and test sets.
# A preliminary exploratory analysis will be conducted to examine each of the features of the dataset to determine potential "biases" that 
# may confound and reduce the predictive accuracy of our models.
# Cleaning of the dataset will remove NAs and ensure that the data is in tidy form. Data visualization in the form of histograms and 
# scatter plots will be woven into the exploratory analysis and modeling to enhance presentation.
# The Modeling Approach will be based on the insights gleaned from the exploratory analysis and will be refined to create a 
# Final Validation Model with an RMSE less than .8649.
# This Final Model will feature User, Movie and Movie-Age Effects with Regularization to achieve this target.

### Data Preparation and Required Packages ###

# Install the pacman package
if(!require(pacman)) install.packages("pacman", repos = "http://cran.us.r-project.org")

### Load the required libraries ###
# If a package below is missing, p_load will automatically download it from CRAN
pacman::p_load(tidyverse, ggplot2, ggthemes, data.table, lubridate, caret, knitr, 
               scales, treemapify)

# All Data for the MovieLens Dataset Will be obtained from the following sources:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

### Data Preparation ###
# Download File
dl <-tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)
# Create the Data Frame "ratings" using fread from library(data.table)
ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <-str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)

colnames(movies) <-c("movieId", "title", "genres")

movies <-as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                          title = as.character(title),
                                          genres = as.character(genres))

movielens <-left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
# Set Seed to 1
set.seed(1, sample.kind="Rounding")
test_index <-createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <-movielens[-test_index,]
temp <-movielens[test_index,]
# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <-anti_join(temp, validation)
edx <-rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)

## Partition Train and Test Sets:
# To begin, we must first partition training and test sets to be used in our later models
# Similarly, we Will only partition 10% of the MovieLens Data for the test set
set.seed(1, sample.kind = "Rounding")
test_index <-createDataPartition(y = edx$rating, times = 1, p = 0.1, list = F)
edx_train <-edx[-test_index,]
edx_temp <-edx[test_index,]

# Again, confirm userId and movieId are in both the train and test sets
edx_test <-edx_temp %>%
  semi_join(edx_train, by = "movieId") %>%
  semi_join(edx_train, by = "userId")

# Add the Rows removed from the edx_test back into edx_train
removed <-anti_join(edx_temp, edx_test)
edx_train <-rbind(edx_train, removed)
rm(edx_temp, test_index, removed)

### Note: The only changes made to the validation set will be a transformed timestamp column as well as the addition of a column titled "MovieAge."

### Begin analyzing the data ###

# Confirm the Data is Tidy: Note that each row has only one observation
edx %>% as_tibble()

## Preliminary Data Exploration of the edx dataset / Confirm dimensions
glimpse(edx)
dim(edx)
# We learn that there are 9000055 Rows & 6 Columns: userId, movieId, rating, timestamp, title & genres

# Determine the unique number of userIds, movieIds, and genres
edx %>% summarize(unique_users = length(unique(userId)),
                  unique_movies = length(unique(movieId)),
                  unique_genres = length(unique(genres)))
# Note that there are 69878 unique userIds, 10,677 unique movieIds, and 797 unique combinations of genres

#### Data Exploration and Visualization of Individual Features ###

## Users: Let's Visually Interpret the Distribution of the Number of Ratings by Users
edx %>% group_by(userId) %>% summarize(n_ratings = n()) %>% 
  ggplot(aes(n_ratings))+
    geom_histogram(fill = "slategray3", color = "black", bins = 35)+
      scale_x_log10()+
        ggtitle("User Distribution")+
          xlab("Ratings")+
            ylab("Users")+
              theme_solarized_2(light = F)+
                theme(plot.title = element_text(hjust = 0.5))
# It is clear that most users rate a few number of films and that the distribution is right skewed

## Movies: Now we will examine the Distribution of Ratings vs Movies
edx %>% group_by(movieId) %>% summarize(n_ratings = n()) %>% 
  ggplot(aes(n_ratings))+
      geom_histogram(fill = "slategray3", color = "black", bins = 35)+
        scale_x_log10()+
          ggtitle("Movies Distribution")+
            xlab("Ratings")+
              ylab("Movies")+
                theme_solarized_2(light = F)+
                  theme(plot.title = element_text(hjust = 0.5))
# The distribution appears to be nearly symmetric which is logical as more popular films tend to be rated more frequently than less popular films.
# The fact that there are a number of films with fewer ratings implies potential biases may affect our recommendation system.

## Ratings: First we determine that there are 10 different ratings users can award the films.
length(unique(edx$rating))

# These Ratings are: 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5 & 5.0.
unique_ratings <-unique(edx$rating)
sort(unique_ratings)

# View a Tibble of the Ratings Distribution
edx %>% group_by(rating) %>% summarize(ratings_sum = n()) %>%
  arrange(desc(ratings_sum))
# A rating of "4" is the most popular rating while 0.5 is awarded the least frequently.

# Examine the distribution visually
edx %>% ggplot(aes(rating))+
  geom_histogram(fill = "slategray3", color = "black", bins = 35)+
    ggtitle("Ratings Distribution")+
      xlab("Rating Awarded")+
        ylab("Total Sum of Ratings")+
          theme_solarized_2(light = F)+
            theme(plot.title = element_text(hjust = 0.5))
# The histogram confirms most viewers tended to award a 3 or above.

# Check the percentage of ratings >=3
rp <-edx %>% filter(edx$rating >=3)
nrow(rp)/length(edx$rating)
# Over 82% of ratings were at or above a 3.

## Timestamp: this feature will be transformed into column "RatingYear" to make the data more accessible.

# It will be named "RatingYear" to reflect the fact that timestamp refers to the year a movie was rated in.
# (The release year of a film will later be extracted from the title column)

# Convert the timestamp to "RatingYear" for the edx dataset
edx <- edx %>% mutate(timestamp = as.POSIXct(timestamp, origin = "1970-01-01", 
                                             tz = "EST"))
edx$timestamp <- format(edx$timestamp, "%Y")
names(edx)[names(edx) == "timestamp"] <- "RatingYear"
head(edx)

# Do the same for the validation set
validation <- validation %>% mutate(timestamp = as.POSIXct(timestamp, origin = "1970-01-01", 
                                                           tz = "EST"))
validation$timestamp <- format(validation$timestamp, "%Y")
names(validation)[names(validation) == "timestamp"] <- "RatingYear"
head(validation)

# This Process is also applied to the edx_train & edx_test sets for later modeling purposes
edx_train <- edx_train %>% mutate(timestamp = as.POSIXct(timestamp, origin = "1970-01-01", 
                                                         tz = "EST"))
edx_train$timestamp <- format(edx_train$timestamp, "%Y")
names(edx_train)[names(edx_train) == "timestamp"] <- "RatingYear"
head(edx_train)
edx_test <-edx_test %>% mutate(timestamp = as.POSIXct(timestamp, origin = "1970-01-01", 
                                                      tz = "EST"))
edx_test$timestamp <- format(edx_test$timestamp, "%Y")
names(edx_test)[names(edx_test) == "timestamp"] <- "RatingYear"
head(edx_test)

# A Quick Check of the range tells us all ratings have taken place between 1995 & 2009
range(edx$RatingYear)

# Coerce RatingYear from character to numeric to plot the histogram
edx$RatingYear <-as.numeric(edx$RatingYear)
str(edx)

# A visualization of the RatingYear feature shows in Which years most ratings occurred
edx %>% ggplot(aes(RatingYear))+
  geom_histogram(fill = "slategray3", color = "black", bins = 35)+
    ggtitle("User Distribution")+
      xlab("Year")+
        ylab("Users")+
          theme_solarized_2(light = F)+
            theme(plot.title = element_text(hjust = 0.5))
# We observe that 1996, 2000 and 2005 are the years in which most films were rated

# Check the titles, ratingYear & ratings of the top 50 movies with the highest sums of ratings
edx %>% group_by(RatingYear, title) %>% 
  summarize(Ratings_Sum = n(), Average_Rating = mean(rating)) %>%
  mutate(Average_Rating = sprintf("%0.2f", Average_Rating)) %>%
  arrange(-Ratings_Sum) %>% print(n = 50)

# A quick analysis of the top 50 movies with the highest number of ratings reveals the vast majority were hits at the box office like "Batman" & "Forrest Gump"
# Additionally, the average rating for every film was above a 3 except for "Ace Ventura: Pet Detective" (2.94) & "Dumb & Dumber" (2.83)

## Genres: Next we begin our exploration of the Genre Feature

# Separate into Individual Genres for each row in a new data frame for further exploratory analysis: note that now there are only 19 distinct genres
edx_genres <-edx %>% separate_rows(genres, sep = "\\|")

# Sum of Movie Ratings per Genre
edx_genres %>%
  group_by(genres) %>% summarize(Ratings_Sum = n(), Average_Rating = mean(rating)) %>%
  arrange(-Ratings_Sum)
# Out of the 19 listed genres, the Top 5 are: Drama, Comedy, Action, & Thriller with IMAX at the bottom
# IMAX being at the bottom could potentially obfuscate modeling as it is more so a venue than a genre

# Confirm this with a treemap based on the Sum of the Ratings
tm <-edx_genres %>%
  group_by(genres) %>% summarize(Ratings_Sum = n()) %>%
  arrange(-Ratings_Sum)

tm %>% ggplot(aes(area = Ratings_Sum, fill = genres, label = genres))+
  geom_treemap()+
  geom_treemap_text(fontface = "italic", col = "white", place = "center",
                    grow = TRUE)

# Arrange the Genres by Mean Rating
edx_genres %>%
  group_by(genres) %>% summarize(Ratings_Sum = n(), Average_Rating = mean(rating)) %>%
  arrange(-Average_Rating)

# The Top 5 by Mean Rating are: Film-Noir, War, IMAX, Mystery, & Drama
# They generally have fewer sums of ratings which could skew our data

# Now let's these observe these visually:
# First we must coerce genres from characters to factors
edx$genres <-as.factor(edx$genres)
edx_genres$genres <-as.factor(edx_genres$genres)
class(edx_genres$genres)

# Sum of Movie Ratings per Genre
sr_bar <-edx_genres %>% group_by(genres) %>% summarize(Ratings_Sum = n())
sr_bar %>% ggplot(aes(x = reorder(genres, Ratings_Sum), y = Ratings_Sum))+
  geom_bar(stat = "identity",  fill = "slategray3", color = "black")+
    ggtitle("Genre Distribution")+
      xlab("Genres")+
        ylab("Sum of Ratings")+
          coord_flip()+
            theme_solarized_2(light = F)+
              theme(plot.title = element_text(hjust = 0.5))

# Mean Rating per Genre
ar_bar <-edx_genres %>% group_by(genres) %>% summarize(avg_rating = mean(rating)) %>%
  arrange(-avg_rating)
ar_bar %>% ggplot(aes(x = reorder(genres, avg_rating), y = avg_rating))+
  geom_bar(stat = "identity", fill = "slategray3", color = "black")+
    ggtitle("Mean Rating by Genre")+
      xlab("Genres")+
        ylab("Mean Rating")+
          coord_flip()+
            theme_solarized_2(light = F)+
              theme(plot.title = element_text(hjust = 0.5))

## Title: Extract the Year a Film was Released by separating it from the title column
yearreleaseda <-as.numeric(str_sub(edx$title, start = -5, end = -2))
edx <- edx %>% mutate(yearReleased = yearreleaseda)
head(edx)

# Do the same for the validation set
yearreleasedb <-as.numeric(str_sub(validation$title, start = -5, end = -2))
validation <- validation %>% mutate(yearReleased = yearreleasedb)
head(validation)

# This Process is also applied to edx_train & edx_test for later modeling purposes
yearreleasedc <-as.numeric(str_sub(edx_train$title, start = -5, end = -2))
edx_train <- edx_train %>% mutate(yearReleased = yearreleasedc)
head(edx_train)
yearreleasedd <-as.numeric(str_sub(edx_test$title, start = -5, end = -2))
edx_test <- edx_test %>% mutate(yearReleased = yearreleasedd)
head(edx_test)

# Use the newly defined "yearReleased" column to add "MovieAge" column
edx <-edx %>% mutate(MovieAge = 2020 - yearReleased)
validation <-validation %>% mutate(MovieAge = 2020 - yearReleased)
edx_train <-edx_train %>% mutate(MovieAge = 2020 - yearReleased)
edx_test <-edx_test %>% mutate(MovieAge = 2020 - yearReleased)

# Data Analysis will be conducted on MovieAge to determine the significance of a potential Age Effects.

# The Mean MovieAge is 29.78 years while the Median is 26.
summary(edx$MovieAge)

# Let's explore a scatter plot of MovieAge and Mean Ratings
edx %>% group_by(MovieAge) %>% summarize(Avg_MR = mean(rating)) %>% 
  ggplot(aes(MovieAge, Avg_MR))+
    geom_point(color = "slategray3")+
      geom_smooth(method = "loess")+
        ggtitle("Movie Age & Average Rating")+
          xlab("Movie Age")+
            ylab("Mean Rating")+
              theme_solarized_2(light = F)+
                theme(plot.title = element_text(hjust = 0.5))
# It is apparent that there is a positive correlation between the two features as evidenced by the generally positive slope of the line of best fit.
# This could be the result of users awarding higher ratings to films that tend to be older and are often regarded as "classics."
# As a result, we can infer there may be meaningful Movie Age Effects

### Modeling ###
# Based on the data analysis, User, Movie, & Movie Age Effects seem to influence the overall ratings most heavily. 
# As such, they will be incorporated as either individual or integrated features of our machine learning models.
# The individual and cumulative results of the models will be published after each model.

### Begin Modeling: Benchmarking Model ###
# Define RMSE
RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
}

# The Benchmarking Model using Naive RMSE based on the mean of the edx_train
edx_train_mu <-mean(edx_train$rating)
NRMSE_M1 <- RMSE(edx_test$rating, edx_train_mu)

# Table the Results
results_table <-tibble(Model_Type = "NRMSE", RMSE = NRMSE_M1) %>% 
  mutate(RMSE = sprintf("%0.4f", RMSE))
results_table
# The Naive RMSE is found to be about 1.06

# Creating any other similar model by plugging in the median or any other random number will always produce a less desirable RMSE.
edx_train_median <-median(edx_train$rating)
MM_M2 <-RMSE(edx_test$rating, edx_train_median)

# Table the Results
results_table <-tibble(Model_Type = c("NRMSE", "Median_Model"),
                       RMSE = c(NRMSE_M1, MM_M2)) %>% 
  mutate(RMSE = sprintf("%0.4f", RMSE))
results_table
# The Median Model is shown to have an RMSE of about 1.16.

## Movie Effects Model:
bi <- edx_train %>% group_by(movieId) %>%
  summarize(b_i = mean(rating - edx_train_mu))

# Let's first visualize the distribution
bi %>% ggplot(aes(b_i))+
  geom_histogram(fill = "slategray3", color = "black", bins = 35)+
    ggtitle("Movie Effects Distribution")+
      xlab("Effects")+
        ylab("Count")+
          theme_solarized_2(light = F)+
            theme(plot.title = element_text(hjust = 0.5))

# Create the Prediction
prediction_bi <-edx_train_mu + edx_test %>%
  left_join(bi, by = "movieId") %>% .$b_i
MEM_M3 <-RMSE(edx_test$rating, prediction_bi)

# Table the Results
results_table <-tibble(Model_Type = c("NRMSE", "Median_Model", "Movie Effects"),
                       RMSE = c(NRMSE_M1, MM_M2, MEM_M3)) %>% 
  mutate(RMSE = sprintf("%0.4f", RMSE))
results_table
# The Movie Effects Model is shown significantly improve the RMSE to roughly .943.

## Adding User Effects
bu <-edx_train %>% left_join(bi, by = "movieId") %>% group_by(userId) %>%
  summarize(b_u = mean(rating - edx_train_mu - b_i))

# Visualize User Effects
bu %>% ggplot(aes(b_u))+
  geom_histogram(fill = "slategray3", color = "black", bins = 35)+
    ggtitle("User Effects Distribution")+
      xlab("Effects")+
        ylab("Count")+
          theme_solarized_2(light = F)+
            theme(plot.title = element_text(hjust = 0.5))
# The data appears to be nearly normally distributed.

# Create the Prediction
prediction_bu <-edx_test %>% left_join(bi, by = "movieId") %>%
  left_join(bu, by = "userId") %>%
  mutate(predictions = edx_train_mu + b_i + b_u) %>% .$predictions
UEM_M4 <-RMSE(edx_test$rating, prediction_bu)

# Table the Results
results_table <-tibble(Model_Type = c("NRMSE", "Median_Model", "Movie Effects", "Movie & User Effects"),
                       RMSE = c(NRMSE_M1, MM_M2, MEM_M3, UEM_M4)) %>% 
  mutate(RMSE = sprintf("%0.4f", RMSE))
results_table
# The Movie & User Effects Model is shown to further improve the RMSE to .8647.

## Adding Movie Age Effects: This Model Combines User, Movie & Movie Age Effects
ba <- edx_train %>%
  left_join(bi, by="movieId") %>% left_join(bu, by ="userId") %>%
  group_by(MovieAge) %>% summarize(b_a = mean(rating - b_i - b_u - edx_train_mu))

# Visualization of Movie Age Effects
ba %>% ggplot(aes(b_a))+
  geom_histogram(fill = "slategray3", color = "black", bins = 35)+
    ggtitle("Movie Age Distribution")+
      xlab("Effects")+
        ylab("Count")+
          theme_solarized_2(light = F)+
            theme(plot.title = element_text(hjust = 0.5))
# The range of the distribution is much wider with denser clusters between 0 & 0.5 and outliers around .20.

# Create the Prediction
predictions_ma <- edx_test %>% 
  left_join(bi, by = "movieId") %>% left_join(bu, by = "userId") %>%
  left_join(ba, by = "MovieAge") %>%  mutate(predictions = edx_train_mu + b_i + b_u + b_a) %>% 
  .$predictions
UMMAE_M5 <-RMSE(edx_test$rating, predictions_ma)

# Table the Results
results_table <-tibble(Model_Type = c("NRMSE", "Median_Model", "Movie Effects", 
                                      "Movie & User Effects",
                                      "User, Movie & Movie Age Effects"),
                       RMSE = c(NRMSE_M1, MM_M2, MEM_M3, UEM_M4, UMMAE_M5)) %>% 
  mutate(RMSE = sprintf("%0.4f", RMSE))
results_table
# The User, Movie & Movie Age Effects Model shows a marginal improvement with an RMSE of .8643.

## Movie & User Effects Model w/Regularization:

# Build a function using sapply to begin regularization: adding a tuning parameter lambda to minimize the RMSE.
# This function penalizes outliers from bi & bu such as users & movies with very few ratings.
lambdasR <-seq(0, 10, 1)
RMSES <- sapply(lambdasR, function(l){
  edx_train_mu <- mean(edx_train$rating)
  
  b_i <- edx_train %>%
    group_by(movieId) %>%
    summarize(b_i = sum(rating - edx_train_mu)/(n() + l))
  
  b_u <- edx_train %>%
    left_join(b_i, by='movieId') %>% 
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - edx_train_mu)/(n() +l))
  
  predicted_ratings <- edx_test %>%
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    mutate(predictions = edx_train_mu + b_i +  b_u) %>% .$predictions
  
  return(RMSE(predicted_ratings, edx_test$rating))
})

# Determine which lambda minimizes the RMSE
lambda <- lambdasR[which.min(RMSES)]
lambda
# A lambda of 5 is shown to be the best Tune

# The Scatterplot confirms this
qplot(lambdasR, RMSES)

# Building the Movie & User Effects Model w/Regularization
b_i <- edx_train %>% 
  group_by(movieId) %>%
  summarize(b_i = sum(rating - edx_train_mu)/(n()+lambda))
b_u <-edx_train %>% 
  left_join(b_i, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - b_i - edx_train_mu)/(n()+lambda))
reg_prediction <- edx_test %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  mutate(predictions = edx_train_mu + b_i + b_u) %>% .$predictions

UMEM_REG_M6 <-RMSE(edx_test$rating, reg_prediction)

# Table the Results
results_table <-tibble(Model_Type = c("NRMSE", "Median_Model", "Movie Effects", 
                                      "Movie & User Effects",
                                      "Movie, User & Movie Age Effects",
                                      "Movie & User Effects w/Regularization"),
                       RMSE = c(NRMSE_M1, MM_M2, MEM_M3, UEM_M4, 
                                UMMAE_M5, UMEM_REG_M6)) %>% 
  mutate(RMSE = sprintf("%0.6f", RMSE))
results_table
# The Regularized Movie and User Effects model further reduces the RMSE to .8641.

## Movie, User, & Movie Age Effects Model w/Regularization:

# Create another function Using sapply to begin regularization: adding a tuning parameter lambda to minimize RMSE.
lambdasM <-seq(0, 10, 1)
RMSES2 <-sapply(lambdasM, function(l){
  edx_train_mu <-mean(edx_train$rating)
  
  b_i <-edx_train %>%
    group_by(movieId) %>%
    summarize(b_i = sum(rating - edx_train_mu)/(n() + l))
  
  b_u <-edx_train %>%
    left_join(b_i, by='movieId') %>% 
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - edx_train_mu)/(n() +l))
  
  b_a <-edx_train %>% 
    left_join(b_i, by = "movieId") %>% left_join(b_u, by = "userId") %>%
    group_by(MovieAge) %>%
    summarize(b_a = sum(rating - b_i - b_u - edx_train_mu)/(n()+l))
  
  predicted_ratings <-edx_test %>%
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    left_join(b_a, by = "MovieAge") %>%
    mutate(predictions = edx_train_mu + b_i + b_u + b_a) %>% .$predictions
  
  return(RMSE(predicted_ratings, edx_test$rating))
})
lambda2 <- lambdasM[which.min(RMSES2)]
lambda2
# A lambda of 5 is yet again shown to be the best Tune for this model.

# This is confirmed by the scatter plot
qplot(lambdasM, RMSES2)

# Build the User, Movie & Movie Age Effects Model with Regularization:
b_i <- edx_train %>% 
  group_by(movieId) %>%
  summarize(b_i = sum(rating - edx_train_mu)/(n()+lambda2))
b_u <-edx_train %>% 
  left_join(b_i, by = "movieId") %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - b_i - edx_train_mu)/(n()+lambda2))
b_a <-edx_train %>% 
  left_join(b_i, by = "movieId") %>% left_join(b_u, by = "userId") %>%
  group_by(MovieAge) %>%
  summarize(b_a = sum(rating - b_i - b_u - edx_train_mu)/(n()+lambda2))
reg_prediction2 <- edx_test %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  left_join(b_a, by = "MovieAge") %>%
  mutate(predictions = edx_train_mu + b_i + b_u + b_a) %>% .$predictions

UMMAE_REG_M7 <-RMSE(edx_test$rating, reg_prediction2)

#Table the Results
results_table <-tibble(Model_Type = c("NRMSE", "Median_Model", "Movie Effects", 
                                      "Movie & User Effects",
                                      "User, Movie & Movie Age Effects",
                                      "Movie & User Effects w/Regularization",
                                      "User, Movie & Movie Age Effects w/Regularization"),
                       RMSE = c(NRMSE_M1, MM_M2, MEM_M3, UEM_M4, 
                                UMMAE_M5, UMEM_REG_M6, UMMAE_REG_M7)) %>% 
  mutate(RMSE = sprintf("%0.5f", RMSE))
results_table
#The Final Model significantly improves upon previous models with an RMSE of .86384.

#Now we will move on to using the edx & validation sets to confirm our Final Model achieves an RMSE < .8649

### VALIDATION ###
# Use the edx and validation sets to confirm  final RMSEs.

## The Benchmarking Model (with validation):
# Uses Naive RMSE based on the mean of the edx dataset with validation
edx_mu <-mean(edx$rating)
FRMSE_M1 <-RMSE(validation$rating, edx_mu)

# Table the Results
results_table <-tibble(Model_Type = ("NRMSE"),
                       Final_RMSE_Validation = (NRMSE_M1)) %>%
  mutate(Final_RMSE_Validation = sprintf("%0.5f", Final_RMSE_Validation))
results_table
# The Benchmarking Mean Model demonstrates an RMSE of about 1.06

## Median Model (with validation):
# A Model Based on the Median of the edx dataset with validation.
edx_med <-median(edx$rating)
FRMSE_M2 <-RMSE(validation$rating, edx_med)

# Table the Results
results_table <-tibble(Model_Type = c("NRMSE", "Median_Model"),
                       Final_RMSE_Validation = c(FRMSE_M1, FRMSE_M2)) %>% 
  mutate(Final_RMSE_Validation = sprintf("%0.5f", Final_RMSE_Validation))
results_table
# The Median Model demonstrates an RMSE of about 1.16.

## Movie Effects Model (with validation):
bi <- edx %>% group_by(movieId) %>%
  summarize(b_i = mean(rating - edx_mu))

# Create the Prediction:
prediction_bi <-edx_mu + validation %>% 
  left_join(bi, by = "movieId") %>% .$b_i
FRMSE_M3 <-RMSE(validation$rating, prediction_bi)

# Table the Results
results_table <-tibble(Model_Type = c("NRMSE", "Median_Model", "Movie Effects"),
                       Final_RMSE_Validation = c(FRMSE_M1, FRMSE_M2, FRMSE_M3)) %>% 
  mutate(Final_RMSE_Validation = sprintf("%0.5f", Final_RMSE_Validation))
results_table

# The Movie Effects Model improves upon the Benchmarking Model with an RMSE of 0.9439.

## Movie & User Effects Model (with validation):
bu <-edx %>% left_join(bi, by = "movieId") %>% group_by(userId) %>%
  summarize(b_u = mean(rating - edx_mu - b_i))

# Create the Prediction:
prediction_bu <-validation %>% left_join(bi, by = "movieId") %>%
  left_join(bu, by = "userId") %>%
  mutate(predictions = edx_mu + b_i + b_u) %>% .$predictions
FRMSE_M4 <-RMSE(validation$rating, prediction_bu)

# Table the Results
results_table <-tibble(Model_Type = c("NRMSE", "Median_Model", "Movie Effects",
                                      "Movie & User Effects"),
                       Final_RMSE_Validation = c(FRMSE_M1, FRMSE_M2, FRMSE_M3,
                                                 FRMSE_M4)) %>% 
  mutate(Final_RMSE_Validation = sprintf("%0.5f", Final_RMSE_Validation))
results_table

## Movie, User & Movie Age Effects (with validation):
ba <- edx %>%
  left_join(bi, by = "movieId") %>% left_join(bu, by = "userId") %>%
  group_by(MovieAge) %>% summarize(b_a = mean(rating - b_i - b_u - edx_mu))

# Create the Prediction:
predictions_ma <- validation %>% 
  left_join(bi, by = "movieId") %>% left_join(bu, by = "userId") %>%
  left_join(ba, by = "MovieAge") %>%  mutate(predictions = edx_mu + b_i + b_u + b_a) %>% 
  .$predictions
FRMSE_M5 <-RMSE(validation$rating, predictions_ma)

# Table the Results
results_table <-tibble(Model_Type = c("NRMSE", "Median_Model", "Movie Effects",
                                      "Movie & User Effects",
                                      "Movie, User, & Movie Age Effects"),
                       Final_RMSE_Validation = c(FRMSE_M1, FRMSE_M2, FRMSE_M3,
                                                 FRMSE_M4, FRMSE_M5)) %>% 
  mutate(Final_RMSE_Validation = sprintf("%0.5f", Final_RMSE_Validation))
results_table
# As demonstrated below, the Movie Age Effects Model further improves upon the User & Movie Effects Model with an RMSE of .865.

## Movie & User Effects w/Regularizataion (validation):
# Build a Function Using sapply to begin regularization: adding a tuning parameter lambda to minimize RMSE.
# A lambda of 5 was shown to be the best Tune for the train and test sets of this Regularized Model and therefore will be used on the validation set.
lambda

# Building the Movie & User Effects Model with Regularization:
b_i <-edx %>% 
  group_by(movieId) %>%
  summarize(b_i = sum(rating - edx_mu)/(n()+lambda))
b_u <-edx %>% 
  left_join(b_i, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - b_i - edx_mu)/(n()+lambda))
reg_prediction <-validation %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  mutate(predictions = edx_mu + b_i + b_u) %>% .$predictions

FRMSE_M6 <-RMSE(validation$rating, reg_prediction)

# Table the Results
results_table <-tibble(Model_Type = c("NRMSE", "Median_Model", "Movie Effects",
                                      "Movie & User Effects",
                                      "Movie, User, & Movie Age Effects",
                                      "Movie & User Effects w/Regularization"),
                       Final_RMSE_Validation = c(FRMSE_M1, FRMSE_M2, FRMSE_M3,
                                                 FRMSE_M4, FRMSE_M5,
                                                 FRMSE_M6)) %>% 
  mutate(Final_RMSE_Validation = sprintf("%0.5f", 
                                         Final_RMSE_Validation))
results_table
# This Regularized Model Achieves an RMSE of .86482, but let's see if we can do better with our Final Validation Model.


## Final Model 7: Movie, User & Movie Age Effects w/Regularization (validation) 
# A lambda of 5 was shown to be the best Tune for the train and test sets of this Regularized Model as well and therefore will be used on the validation set.
lambda2

# Building the User, Movie & Movie Age Effects Model with Regularization:
b_i <- edx %>% 
  group_by(movieId) %>%
  summarize(b_i = sum(rating - edx_mu)/(n()+lambda2))
b_u <-edx %>% 
  left_join(b_i, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - b_i - edx_mu)/(n()+lambda2))
b_a <-edx %>% 
  left_join(b_i, by="movieId") %>% left_join(b_u, by= "userId") %>%
  group_by(MovieAge) %>%
  summarize(b_a = sum(rating - b_i - b_u - edx_mu)/(n()+lambda2))
reg_prediction2 <-validation %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  left_join(b_a, by = "MovieAge") %>%
  mutate(predictions = edx_mu + b_i + b_u + b_a) %>% .$predictions

FRMSE_M7 <-RMSE(validation$rating, reg_prediction2)

# Table the Results
results_table <-tibble(Model_Type = c("NRMSE", "Median_Model", "Movie Effects",
                                      "Movie & User Effects",
                                      "Movie, User, & Movie Age Effects",
                                      "Movie & User Effects w/Regularization",
                                      "Movie, User & Movie Age Effects w/Regularization"),
                       Final_RMSE_Validation = c(FRMSE_M1, FRMSE_M2, FRMSE_M3,
                                                 FRMSE_M4, FRMSE_M5,
                                                 FRMSE_M6, FRMSE_M7)) %>% 
  mutate(Final_RMSE_Validation = sprintf("%0.5f", 
                                         Final_RMSE_Validation))
results_table

# Table the train & test_set Results against those of the validation set
results_table <-tibble(Model_Type = c("NRMSE", "Median_Model", "Movie Effects", 
                                      "Movie & User Effects",
                                      "Movie, User & Movie Age Effects",
                                      "Movie & User Effects w/Regularization",
                                      "User, Movie & Movie Age Effects w/Regularization"),
                       RMSE = c(NRMSE_M1, MM_M2, MEM_M3, UEM_M4, 
                                UMMAE_M5, UMEM_REG_M6, UMMAE_REG_M7),
                       Final_RMSE_Validation = c(FRMSE_M1, FRMSE_M2, 
                                                 FRMSE_M3, FRMSE_M4,
                                                 FRMSE_M5, FRMSE_M6,
                                                 FRMSE_M7)) %>%
  mutate(Final_RMSE_Validation = sprintf("%0.5f", 
                                         Final_RMSE_Validation)) %>%
  mutate(RMSE = sprintf("%0.5f", RMSE))

results_table

# The kable function in knitr also allows us to generate a table of the results:
results_table %>% knitr::kable()

# The Lowest RMSE using the validation set is the Final Validation Model using Regularized User, Movie & Movie Age Effects.
# This Final Model achieves an RMSE of .86452.

### Conclusion ### 

# While the Final Model which was comprised of Movie, User, and Movie Age Effects with Regularization performed well with an RMSE of .86452, there are additional biases that could have been explored to further improve the accuracy of the model.
# Additionally, methods such as matrix factorization using the recosystem package could be utilized to provide significant improvements in the RMSE.
# While more advanced models including Distributed Random Forests and those based on Singular Value Decomposition (made famous by Simon Funk during the Netflix Challenge) generate higher levels of accuracy, they are also far more computationally intensive.
# Therefore hardware or financial limitations might exist for those attempting to develop more sophisticated machine-learning models without spinning on a cloud-based service. 
# In the future, models involving K-Nearest-Neighbors and Collaborative Filtering with cosine similarity are thought to continue making strides and improve the overall user experience for streamers everywhere.

### Citations ###

# Irizarry, Rafael A., "Introduction to Data Science: Data Analysis and Prediction Algorithms in R"
# https://rafalab.github.io/dsbook/
  
  
# Feuerverger, A., He, Y., & Khatri, S. (2012). Statistical significance of the Netflix challenge. Statistical Science, 27(2), 202-231.
# https://www.jstor.org/stable/41714795?seq=1